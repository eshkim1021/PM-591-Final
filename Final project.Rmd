---
title: "Final project"
date: "Due April 30, 2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(data.table)
library(mlr)
library(dplyr)
library(randomForest)
library(rpart)

data <- read.csv("NIS2012-200k.csv", header = TRUE, stringsAsFactors = TRUE)

data.dt <- data.frame(data)

```
<br>
The final project requires that you build a predictive model based on real data -- your own or the provided National Impatient data-- and a paper-style short report (2-3 of pages long) describing the problem, the approach(es) taken, and the results. Below is a *guideline* structure for the report. You should use the section breakdown into intro, methods, results, conclusions/discussion but don't have to necessarily include every element listed below within those sections. And you may want to include elements not listed below. Use your judgement.

### Introduction

  The National Impatient Sample (NIS) data, collected by the Healthcare Cost and Utilization Project (HCUP), is the largest publicly available dataset that contains information on inpatient healthcare in hospitals throughout the United States. The NIS is used by policymakers and health officials to make national estimates of healthcare utilization, and observe key features of inpatient care. The NIS was first started in 1998 by the Healthcare Cost and Utilization Project, and contains information such as patient demographics, classification of diseases, total hospital bill, length of stay, and many other features that characterize hospital care. The goal of this assignment will be to build a model to predict impatient mortality an determine what factors contribute a increased risk of death during hospitalization. 

  The data that will be used in this assignment consists of a random subset of 200,000 patients from the 2012 National Impatient Sample. The data was taken from the Healthcare Cost and Ultilization Project (HCUP), which is the largest collection of hospital care data in the United States. The data was taken from discharge records from all hospitals that are participating with the HCUP, and use state guidelines to help identify the hospitals that qualify for the data collection process. 47 states and the District of Columbia participate in the NIS, and data is available for hospitals in those states. The outcome of interest is the inpatient mortality, of whether the patient died during the period of hospitalization. Features such as patient demographic, severity of disease, risk of mortality, and comorbidities were incorpated to determine if a patient was likely to die during hospitalization. This can be used to identify features that increase the risk of patient mortality in hospitals and seek to prevent such deaths in the future. 

1. Describe the problem explaining in particular why prediction is of primary interest (inference could also be of interest but there has to be a good reason for wanting to predict a particular outcome)

2. Describe the data (e.g. data source, data collection, outcome of interest, available features, sample size, missing data, etc.)

### Methods

First the relevant features to the outcome of interest was sorted out from the 175 original features that were present. 

```{r}
names <- c("DIED", "APRDRG_Risk_Mortality","AGE","APRDRG_Severity","CM_AIDS","CM_ALCOHOL","CM_ANEMDEF","CM_ARTH","CM_BLDLOSS","CM_CHF","CM_CHRNLUNG","CM_COAG","CM_DEPRESS","CM_DM", "CM_DMCX","CM_DRUG","CM_HTN_C","CM_HYPOTHY","CM_LIVER","CM_LYMPH","CM_LYTES","CM_METS","CM_NEURO","CM_OBESE","CM_PARA","CM_PERIVASC","CM_PSYCH","CM_PULMCIRC","CM_RENLFAIL","CM_TUMOR","CM_ULCER","CM_VALVE","CM_WGHTLOSS","FEMALE","HOSP_DIVISION","LOS","NCHRONIC","NDX","NEOMAT","PAY1","RACE","YEAR","ZIPINC_QRTL","ORPROC") #list the features that will be included 


refine_data <- data.dt %>% select(names)
```

Then then data was then reevaluated and factors were added when necessary. 

```{r}
refine_data$DIED <- factor(refine_data$DIED,
                           levels = c(0,1),
                           labels = c("Alive","Died"))

refine_data$APRDRG_Risk_Mortality <- factor(refine_data$APRDRG_Risk_Mortality,
                                            levels = c(0,1,2,3,4), 
                                            labels = c("Not specified","Minor Likelihood","Moderate Likelihood","Major Likelihood","Extreme Likelihood"))


refine_data$APRDRG_Severity <- factor(refine_data$APRDRG_Severity,
                                      levels = c(0,1,2,3,4),
                                      labels = c("Not specified","Minor Loss of Function","Moderate Loss of Function","Major Loss of Function","Extreme Loss of Function"))

factor_names <- c("CM_AIDS","CM_ALCOHOL","CM_ANEMDEF","CM_ARTH","CM_BLDLOSS","CM_CHF","CM_CHRNLUNG","CM_COAG","CM_DEPRESS","CM_DM", "CM_DMCX","CM_DRUG","CM_HTN_C","CM_HYPOTHY","CM_LIVER","CM_LYMPH","CM_LYTES","CM_METS","CM_NEURO","CM_OBESE","CM_PARA","CM_PERIVASC","CM_PSYCH","CM_PULMCIRC","CM_RENLFAIL","CM_TUMOR","CM_ULCER","CM_VALVE","CM_WGHTLOSS","FEMALE","HOSP_DIVISION","NEOMAT")

refine_data[factor_names] <- lapply(refine_data[factor_names],factor)

refine_data$PAY1 <- factor(refine_data$PAY1,
                           levels = c(1,2,3,4,5,6),
                           labels = c("Medicare","Medicaid","Private","Self-Pay","No Charge","Other"))

refine_data$RACE <- factor(refine_data$RACE,
                           levels = c(1,2,3,4,5,6),
                           labels = c("White","Black","Hispanic","Asian","Native American","Other"))


refine_data <- na.omit(refine_data)

summary(refine_data)

```

1. Describe any data pre-processing steps (e.g. cleaning, recoding, variable transformation, dealing with missing data, selection of features to be included in your models, etc)

Out of the 175 possible features that were present in the original dataset, only 44 variables were selected to be included in analysis and model building. These 44 include data regarding patient demographics (age, race, gender), comorbidities (such as alcohol abuse and COPD), and the risks of patient mortality. Each variable was examined and was made into factor variables as was appropriate. A majority of the features were converted into dummy variables, however some remained as strings and integers. In examining the missing data, there was less than 1% of the total sample size that was missing from the target variable, whether the patient died. Because the sample was small compared to the dataset, the missing values of the target variable were removed before the analysis.

2. Briefly describe the Machine learning methods you will be using and why they are appropriate for your data (e.g. given the sample size and dimensionality of your training data, are you more concerned about bias or variance?)  You should try and compare at least 3 distinct appropriate methods.

  A logistic regression model can be used to predict patient mortality. 
  
  Feature Selection will be used to 

3. Describe how you are splitting the data into testing and training and any resampling strategy used for comparing methods, tuning parameters, and/or model/feature selection.

```{r}
#make task for log reg 
data_tsk <- makeClassifTask(id = "Paitent Mortality", data = refine_data, target = "DIED")
```



```{r}
#make log learner 
data_learn_log <- makeLearner("classif.logreg",
                              predict.type = "prob")

holdout_desc <- makeResampleDesc(method = "Holdout", stratify = TRUE)

set.seed(301)
log_split <- makeResampleInstance(holdout_desc,data_tsk, split = 0.7)

log_train <- log_split$train.inds[[1]];log_test <- log_split$test.inds[[1]]


#use forward subset to determine best result 
ctrl_forward <- makeFeatSelControlSequential(method = "sfs", alpha = 0.01)

log_forward_cv <- makeResampleDesc("CV",iters = 5L)

log_forward <- selectFeatures(learner = data_learn_log,
                              task = data_tsk,
                              resampling     = log_forward_cv,
                              measures = auc, 
                              control = ctrl_forward,
                              show.info = TRUE)

#only Risk of Mortality found to be inmportant, but will include other demographic factors 
analyzeFeatSelResult(log_forward)

#Risk of Mortality, Race, and Length of Stay 
forward_log_data <- refine_data %>% select("DIED","APRDRG_Risk_Mortality","RACE")

#create new task for the new dataset 
log_for_tsk <- makeClassifTask(id = "Paitent Mortality", data = forward_log_data,
                               target = "DIED")

log_for_train <- train(data_learn_log,log_for_tsk, subset = log_train)

log_for_predict <- predict(log_for_train, task = log_for_tsk, subset = log_test)

calculateROCMeasures(log_for_predict)

performance(log_for_predict, measures = list(mmce,acc))

for_log_crossval <- crossval(data_learn_log,log_for_tsk,iters = 10L, stratify = TRUE, measures = mmce)

for_log_crossval$aggr
```

```{r}
library('pROC')
data_glm <- glm(DIED~APRDRG_Risk_Mortality + RACE, family = 'binomial',data = forward_log_data[log_train,])

pred_glm <- factor(predict(data_glm,newdata = forward_log_data[log_test, ],type = 'response') >0.5)


predict_prob_train <- predict(data_glm, newdata = forward_log_data[log_train, ])
predict_prob_test <- predict(data_glm,newdata = forward_log_data[log_test, ])

roc_glm_train <- roc(forward_log_data[log_train,]$DIED,predict_prob_train, ci = TRUE, of = 'auc')
roc_glm_test <- roc(forward_log_data[log_test, ]$DIED,predict_prob_test, ci = TRUE, of = 'auc')
```

```{r}
auc(roc_glm_train)
ci(roc_glm_train)

plot(roc_glm_train, lwd = 4, col = 'red4',cex.axis = 1.3, cex.lab = 1.3)
```

```{r}
auc(roc_glm_test)
ci(roc_glm_test)
#have the auc of the test data 
plot(roc_glm_test,lwd = 4, col = 'red4', cex.axis = 1.3, cex.lab = 1.3)
title(main = "ROC Curve for Patient Mortality (Test Data)")

```


```{r}
#random forest 
split_desc <- makeResampleDesc(method = "Holdout",stratify = TRUE)

set.seed(101)
split <- makeResampleInstance(split_desc,data_tsk,split = 0.7)

rf_train <- split$train.inds[[1]];rf_test <- split$test.inds[[1]]

rpart(DIED ~., data = refine_data[rf_train, ], method = "class",control = list(minsplit = 15,minbucket = 5, cp  = 0))
```

4. If applicabble, describe any model/feature selection used. 

4. If applicabble, describe any tuning parameters and how you will be tuning them. 

5. Describe what performance metric(s) you will be using and why.

### Results
1. Present key summaries (table and/or plots, but plots prefered when both available) of your data (e.g. class frequencies if a classification problem)



2. Report training, validation/cross-validation, and test errors. Present cross-validation plots for tuning parameters if available. Report variable importance (e.g. p-values, model coefficients, Random forest and boosting variable importance).

### Conclusions/discussion
Discuss whether and why the prediction model(s) developed achieved sufficient high accuracy to be usefully deployed to predict new observations.

#Additional notes for those using the NIS data
The data provided consists of a random subset of 200,000 patients from 2012 from the National Impatient Sample (NIS) data collected by the Healthcare Cost and Utilization Project (HCUP). You can find information on the HCUP database at <https://www.hcup-us.ahrq.gov>. You can choose to develop a model to predict death during hospitalization also known as impatient mortality (variable DIED in the dataset) or hospital length of stay (variable LOS in the dataset). For extra credit, you can also choose to predict both. The dataset has a relatively large number of variables. In the provided data dictionary I preselected variables (highlighted) which are both availabe (not all variables in the dictionary are available for 2012) which might be relevant for predicting impatient mortality and/or hospital length of stay. Based on their description and additional info from the HCUP site you should choose which variables among the preselected ones you will consider as features/predictors. You don't have to use them all. There maybe variables that are redundant (capture pretty much the same info others already capture), variables that are too complex (e.g. categorical with way too many levels), or that based on your judgment are unlikely to be important. Be aware that the data is real and has not been pre-processed in any way and you will have to do some data cleaning. For example, you should carefully check the variables you consider as possible predictors for correctness of type (e.g. many numeric variables will be read in as factor variables when you use ``read.csv``), outliers, missing observations, nonsensical values, etc.



